{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8e6ca98f-4366-40ac-8093-3ff28641aad5"
    }
   },
   "source": [
    "# Titanic: to survive or not to survive"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'This code creates a toggle button that will SHOW/HIDE the python code when sharing this notebook on nbviewer'\n",
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "a905aa05-cffc-42bb-8efb-a0dd72be46b7"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmh63\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn import cross_validation as cva\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.ensemble import GradientBoostingClassifier as gbc\n",
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "#from sklearn.cross_validation import KFold\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "full_data = [train, test]\n",
    "all_data = train.append(test)\n",
    "\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Feature Engineering ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "87ab0909-cca7-43b0-b5c1-4aa1b9eea703"
    }
   },
   "source": [
    "### Feature: Age ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "8660a8b4-b4ab-4c70-954f-d3b7c133292a"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmh63\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Deal with NaN values for train and test data. Current strategy is to replace NaN values with a random set of ages within\n",
    "#a designated distance from the mean\n",
    "\n",
    "#Get some statistics\n",
    "age_mean = train['Age'].mean()\n",
    "age_std = train['Age'].std()\n",
    "\n",
    "#Loop through each dataset\n",
    "for dataset in full_data:\n",
    "    age_nan_count = dataset['Age'].isnull().sum()\n",
    "\n",
    "    #Generate random numbers between +-1 std and mean\n",
    "    age_rand = np.random.randint(age_mean-age_std/2, age_mean+age_std/2, size=age_nan_count)\n",
    "    \n",
    "    #Fill in NaN values with mean of entrire set (train + test)\n",
    "    dataset['Age'][np.isnan(dataset[\"Age\"])] = age_rand\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's map a categorical age to test in our classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     CategoricalAge  Survived\n",
      "0    (0.34, 16.336]  0.550000\n",
      "1  (16.336, 32.252]  0.352941\n",
      "2  (32.252, 48.168]  0.374468\n",
      "3  (48.168, 64.084]  0.434783\n",
      "4      (64.084, 80]  0.090909\n"
     ]
    }
   ],
   "source": [
    "#Divide the data into bins. Decided to use pd.cut instead of pd.qcut because survival rates were more diverse\n",
    "train['CategoricalAge'] = pd.cut(train['Age'], 5)\n",
    "print (train[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean())\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['CategoricalAge'] = 0\n",
    "    dataset.loc[dataset['Age']<=16, 'CategoricalAge'] = 0\n",
    "    dataset.loc[(dataset['Age']>16) & (dataset['Age']<=32), 'CategoricalAge'] = 1\n",
    "    dataset.loc[(dataset['Age']>32) & (dataset['Age']<=48), 'CategoricalAge'] = 2\n",
    "    dataset.loc[(dataset['Age']>48) & (dataset['Age']<=64), 'CategoricalAge'] = 3\n",
    "    dataset.loc[dataset['Age']>64, 'CategoricalAge'] = 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "0a8e86aa-e960-49ed-9d49-c2fa3358282b"
    }
   },
   "source": [
    "### Feature: Sex ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "75404577-10ac-4425-ac22-cc5c52944b6b"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sex  Survived\n",
      "0    0  0.168174\n",
      "1    1  0.742268\n",
      "2    2  0.702128\n"
     ]
    }
   ],
   "source": [
    "#Map the Sex column to 0:Male, 1:Female, 2:Child\n",
    "for dataset in full_data:\n",
    "        dataset.loc[dataset['Sex']=='male','Sex'] = 0\n",
    "        dataset.loc[dataset['Sex']=='female','Sex'] = 1\n",
    "        dataset.loc[dataset['Age']<=6,'Sex'] = 2        #labeling the young ones as children\n",
    "        \n",
    "print (train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b5c5eb02-9719-453e-9fb4-6d5d21e691b8"
    }
   },
   "source": [
    "### Feature: Pclass ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "4a5a50cf-874b-4d02-b3ee-f75433a81662"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Survived\n",
      "0       1  0.629630\n",
      "1       2  0.472826\n",
      "2       3  0.242363\n"
     ]
    }
   ],
   "source": [
    "#We have all the Pclass values in numerical form, so no need to fill or map anything\n",
    "print(train[['Pclass','Survived']].groupby('Pclass', as_index=False).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "a13c273f-2997-48ee-83c4-c714701dc8b6"
    }
   },
   "source": [
    "### Feature: Family ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "56199988-df89-41b9-b0d3-4ac4c5e58013"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FamilySize  Survived\n",
      "0           0  0.303538\n",
      "1           1  0.552795\n",
      "2           2  0.578431\n",
      "3           3  0.724138\n",
      "4           4  0.200000\n",
      "5           5  0.136364\n",
      "6           6  0.333333\n",
      "7           7  0.000000\n",
      "8          10  0.000000\n"
     ]
    }
   ],
   "source": [
    "#My thought is that we create two new family features:\n",
    "    #FamilySize: Parch + SibSp\n",
    "    #IsAlone: when family size = 0\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch']\n",
    "    \n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 0, 'IsAlone'] = 1\n",
    "\n",
    "print(train[['FamilySize','Survived']].groupby('FamilySize', as_index=False).mean())\n",
    "#print(train[['IsAlone','Survived']].groupby('IsAlone', as_index=False).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "45b1e205-c4e6-4b03-9747-1aa39117ba2b"
    }
   },
   "source": [
    "### Feature: Name Title ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "63ac298b-bd3a-4b3b-ba17-62a06ad230a6"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Title  Survived\n",
      "0      0  0.156673\n",
      "1      1  0.793651\n",
      "2      2  0.702703\n",
      "3      3  0.575000\n",
      "4      4  0.428571\n",
      "5      5  0.000000\n",
      "6      6  0.400000\n",
      "7      7  0.600000\n"
     ]
    }
   ],
   "source": [
    "#Let's grab the titles of people (Mr, Mrs, etc) and map them to numerical values\n",
    "\n",
    "def get_title(name):\n",
    "    title = re.search('[A-Z][a-z]+\\.', name)\n",
    "    if title:\n",
    "        return(title.group())\n",
    "    return(\"\")\n",
    "\n",
    "title_map = {\n",
    "    'Mr.':0,\n",
    "    'Mrs.':1,\n",
    "    'Miss.':2,\n",
    "    'Master.':3,\n",
    "    'Dr.':4,\n",
    "    'Rev.':5,\n",
    "    'Major.':6,\n",
    "    'Col.':6,\n",
    "    'Mlle.':2,\n",
    "    'Jonkheer.':7,\n",
    "    'Lady.':7,\n",
    "    'Don.':7,\n",
    "    'Dona.':7,\n",
    "    'Countess.':7,\n",
    "    'Capt.':6,\n",
    "    'Sir.':7,\n",
    "    'Mme.':1,\n",
    "    'Ms.':2\n",
    "}\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "    dataset['Title'] = dataset['Title'].map(title_map)\n",
    "    \n",
    "print(train[['Title','Survived']].groupby('Title', as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature: Fare ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CategoricalFare  Survived\n",
      "0                0  0.207358\n",
      "1                1  0.339869\n",
      "2                2  0.462069\n",
      "3                3  0.425676\n",
      "4                4  0.671233\n"
     ]
    }
   ],
   "source": [
    "#Let's take a look at fare. It looks like there are 15 values of $0, which I'm going to assume are missing values.\n",
    "#print(train['Fare'].value_counts().sort_index(ascending=False))\n",
    "#train[train['Fare']==0]\n",
    "\n",
    "#For now, let's fill in any NaN or missing fares with the median of the pclass fare\n",
    "for x in range(1,4):\n",
    "    median = train[train['Pclass']==x]['Fare'].median()\n",
    "    std = train[train['Pclass']==x]['Fare'].std()\n",
    "    #print(median, \" \",std)\n",
    "    \n",
    "    for dataset in full_data:\n",
    "        dataset.loc[(dataset['Pclass']==x) & (dataset['Fare']==0), 'Fare'] = median\n",
    "        dataset.loc[(dataset['Pclass']==x) & (np.isnan(dataset[\"Fare\"])==True), 'Fare'] = median\n",
    "\n",
    "\n",
    "#Creating a CategoricalFare feature\n",
    "pd.qcut(train['Fare'],6).value_counts()\n",
    "\n",
    "# Mapping Fare\n",
    "for dataset in full_data:\n",
    "    dataset['CategoricalFare'] = 0\n",
    "    dataset.loc[dataset['Fare'] <= 8.76, 'CategoricalFare']= 0\n",
    "    dataset.loc[(dataset['Fare'] > 8.76) & (dataset['Fare'] <= 14.5), 'CategoricalFare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.5) & (dataset['Fare'] <= 26.25), 'CategoricalFare'] = 2\n",
    "    dataset.loc[(dataset['Fare'] > 26.25) & (dataset['Fare'] <= 53.1), 'CategoricalFare'] = 3\n",
    "    dataset.loc[dataset['Fare'] > 53.1, 'CategoricalFare']= 4\n",
    "    dataset['CategoricalFare'] = dataset['CategoricalFare'].astype(int)\n",
    "\n",
    "print(train[['CategoricalFare','Survived']].groupby('CategoricalFare', as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3f123d69-dbff-4029-9866-03e237c6c9b4"
    }
   },
   "source": [
    "## Machine Learning Section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "1917576d-8c40-4b7d-a1c1-f96200c9efee"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.814997209363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmh63\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.808225108225\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This did NOT result in any better scores....\n",
    "\n",
    "rand = np.random.rand(len(train)) < 0.5\n",
    "train1 = train[rand]\n",
    "train2 = train[~rand]\n",
    "\n",
    "#The features for the model\n",
    "predictors = ['Pclass', 'Sex', 'CategoricalAge', 'FamilySize', 'Title','CategoricalFare', 'IsAlone']\n",
    "\n",
    "#SOLO random forest classifier \n",
    "alg = rfc(random_state=1, n_estimators=50, min_samples_split=5, min_samples_leaf=5)\n",
    "kf = cva.KFold(train1.shape[0], n_folds=3, random_state=1)\n",
    "scores = cva.cross_val_score(alg, train1[predictors], train1['Survived'], cv=kf)\n",
    "print(scores.mean())\n",
    "\n",
    "alg.fit(train1[predictors], train1['Survived'])\n",
    "train2_preds = alg.predict(train2[predictors])\n",
    "test_preds = alg.predict(test[predictors])\n",
    "\n",
    "train2['Train_Preds'] = train2_preds\n",
    "test['Train_Preds'] = test_preds\n",
    "\n",
    "predictors2 = ['Train_Preds']\n",
    "\n",
    "kf = cva.KFold(train2.shape[0], n_folds=3, random_state=1)\n",
    "scores = cva.cross_val_score(alg, train2[predictors2], train2['Survived'], cv=kf)\n",
    "print(scores.mean())\n",
    "\n",
    "#Let's predict on titanicTest!\n",
    "alg.fit(train2[predictors2], train2['Survived'])\n",
    "predictions = alg.predict(test[predictors2])\n",
    "\n",
    "\n",
    "#Create a submission file\n",
    "submission = pd.DataFrame({\n",
    "       'PassengerId':test['PassengerId'],\n",
    "       'Survived':predictions\n",
    "   })\n",
    "\n",
    "submission.to_csv('titanic_submission.csv',index=False)\n",
    "\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #The features for the model\n",
    "# predictors = ['Pclass', 'Sex', 'CategoricalAge', 'FamilySize', 'Title','CategoricalFare', 'IsAlone']\n",
    "\n",
    "# #SOLO random forest classifier (this resulted in a best submission score of 75%)\n",
    "# alg = rfc(random_state=1, n_estimators=50, min_samples_split=5, min_samples_leaf=5)\n",
    "\n",
    "# #Setting up the cross validation folds\n",
    "# kf = cva.KFold(train.shape[0], n_folds=3, random_state=1)\n",
    "\n",
    "# #Running the algorithm with the kfolds\n",
    "# scores = cva.cross_val_score(alg, train[predictors], train['Survived'], cv=kf)\n",
    "# print(scores.mean())\n",
    "\n",
    "# #Let's predict on titanicTest!\n",
    "# alg.fit(train[predictors], train['Survived'])\n",
    "# predictions = alg.predict(test[predictors])\n",
    "\n",
    "# #Create a submission file\n",
    "# submission = pd.DataFrame({\n",
    "#        'PassengerId':test['PassengerId'],\n",
    "#        'Survived':predictions\n",
    "#    })\n",
    "\n",
    "# submission.to_csv('titanic_submission.csv',index=False)\n",
    "\n",
    "# submission.head()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'This code hides unwanted features when sharing this notebook with through nbviewer'\n",
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "    $('div.output_stderr').hide();\n",
    "  });\n",
    "</script>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "nbpresent": {
   "slides": {
    "80b2b2b4-db19-4eee-a154-088344205550": {
     "id": "80b2b2b4-db19-4eee-a154-088344205550",
     "layout": "manual",
     "prev": null,
     "regions": {
      "284f7a35-eb37-49b6-9e98-ecbf93d72067": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "id": "284f7a35-eb37-49b6-9e98-ecbf93d72067"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
